import multiprocessing
import threading
import time
import traceback

from .base_handler import BaseMultiprocessHandler
from .compat import QueueHandler
from .debug import get_debug_logger


_log = get_debug_logger('starlog.debug.queue_handler')


class MultiprocessHandler(BaseMultiprocessHandler):
    """The MultiprocessHandler sets up a :py:class:`multiprocessing.Queue`. All
    subprocesses sends messages to this queue by using the `emit` method. A
    background thread in the main process retrieves these messages and pushes
    them back to the logging system as if they were generated by the main
    process.

    The MultiprocessHandler is expected to be set up by the main process.

    :param queue: A multiprocessing capable queue. If not set, then a new
        multiprocessing queue is created.
    :param bool manager_queue: If `queue` is `None` and this argument is set
        to `True`, then a new queue is created by calling
        :py:meth:`multiprocessing.managers.SyncManager.Queue`.
    :param str logger: name of the logger where log records are send to in the
        master process.
    """

    def __init__(self, queue=None, manager_queue=True,
                 logger='starlog.logsink'):
        BaseMultiprocessHandler.__init__(self, logger)

        if queue is None:
            if manager_queue:
                manager = multiprocessing.Manager()
                queue = manager.Queue()
            else:
                queue = multiprocessing.Queue()
        else:
            self._check_queue(queue)

        self._queue = queue
        self._qhandler = QueueHandler(queue)

        self._async_listener = self._start_listener_thread(queue)

    def _check_queue(self, queue):
        """Check if ``queue`` has methods .get and .put
        """
        try:
            queue.get
            queue.put
        except AttributeError:
            raise TypeError('queue %r is of unsupported type: %s' % (
                queue, queue.__class__))

    def _start_listener_thread(self, queue):
        _log.info('MultiprocessHandler._start_listener_thread')
        listener = QueueListenerThread(queue, self)
        listener.start()
        return listener

    def forward_to_master(self, record):
        self._qhandler.handle(record)

    def close(self):
        _log.info('MultiprocessHandler.__del__ for %s', self)
        BaseMultiprocessHandler.close(self)

        if self._is_master_process():
            return

        listener_thread = self._async_listener
        if listener_thread is None:
            return

        queue = self._queue
        if queue is None:
            return

        # send signal to shutdown the QueueListenerThread
        try:
            queue.put(None)
        except (IOError, EOFError) as error:
            # probably the queue is already closed
            _log.warn('error while closing QueueListenerThread: %s', error)
            raise

        # wait until the thread consumed the shutdown item
        if not _join_thread(listener_thread, timeout=10):
            _log.warn('QueueListenerThread did not shut down')

        _close_queue(queue)
        _join_queue(queue)
        self._queue = None
        self._async_listener = None


def _join_thread(thread, timeout):
    for trial in range(timeout):
        if not thread.is_alive():
            break

        time.sleep(1)

    return trial == timeout - 1


def _close_queue(queue):
    try:
        queue.close
    except AttributeError:
        pass
    else:
        _log.info('calling queue.close()')
        queue.close()
        _log.info('queue closed')


def _join_queue(queue):
    try:
        queue.join
    except AttributeError:
        pass
    else:
        _log.info('calling queue.join()')
        queue.join()
        _log.info('queue joined')


def _task_done(queue):
    try:
        queue.task_done
    except AttributeError:
        pass
    else:
        _log.info('QueueListenerThread: calling queue.task_done()')
        try:
            queue.task_done()
        except IOError:
            pass


class QueueListenerThread(threading.Thread):
    """Listens for incoming queue messages and forwards them back to the
    corresponding logger, i.e. in the main process.
    """
    def __init__(self, queue, handler, *args, **kwargs):
        super(QueueListenerThread, self).__init__(*args, **kwargs)
        self.setDaemon(True)

        self._queue = queue
        self._handler = handler

    def run(self):
        """Start the main loop. Wait for incoming log records in the queue.
        Each log record is forwarded back to python's standard logger of the
        main process.
        """
        try:
            while True:
                try:
                    # A closed queue results in an IOError in the get() request
                    # only if no timeout is set. A None value in the queue is
                    # a signal to stop the thread.
                    record = self._queue.get()
                    if record is None:
                        _log.info('shutting down QueueListenerThread')
                        break
                    self._process_record(record)
                except (IOError, EOFError):
                    # multiprocessing.managers.Queue returns an EOFError
                    _log.info('exception in QueueListenerThread.run: %s',
                              traceback.format_exc())
                    break
        except Exception:
            _log.warn('exception in QueueListenerThread.run: %s',
                      traceback.format_exc())

        _log.info('QueueListenerThread stopped')

        _task_done(self._queue)

    def _process_record(self, record):
        self._handler.forward_to_sink(record)
